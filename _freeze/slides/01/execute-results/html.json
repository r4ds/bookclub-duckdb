{
  "hash": "750d5ed58f9ec229532c31e6a1b5f22f",
  "result": {
    "engine": "knitr",
    "markdown": "---\nengine: knitr\ntitle: An introduction to DuckDB\n---\n\n# Ô∏èWelcome!\n\n## Logistics\n- All the important bookclub links are under Slack's \"Bookmarks\" tab \n    - [Claim a chapter](https://docs.google.com/spreadsheets/d/1B9WV0Iiv6XYDX49qKWuLkfiCrM0YUkfiCYB6NZH4DkY/edit?gid=0#gid=0)\n    - [Github repository](https://github.com/r4ds/bookclub-duckdb)\n- Potential guest speakers\n\n## Agenda\n- Review Chapter 1\n- Discuss the finer points of contributing to the bookclub github repository\n\n# Chapter 1 \n\n## Learning Goals\n\n- What is DuckDB and why bother learning to use it? \n\n## Basics\n\n- DuckDB is a single-node, in-memory database that intergrates well into many places in the data pipeline. \n- DuckDB is very fast - much faster than `dplyr` or `pandas` for data transformation.\n- The DuckDB IP is owned by the Netherlands Stichting (non-profit) DuckDB Foundation.\n\n## How Fast?\n![Source: DuckDB Labs](/assets/01/duckdb-5.png)\n\n## How Fast?\n\n![Source: DuckDB Labs](/assets/01/duckdb-50.png)\n\n## Where Does DuckDB Fit In?\n\n- DuckDB is an \"in process\" database - it runs in another application's memory space, like R or Python.\n- It can speed up traditional \"small data\" workloads by interfacing with R or Python libraries.\n- It can extend local analysis to data of \"a few hundred gigabytes\".\n- It operate directly \"at the edge\" or \"in the cloud.\" For instance, it can analyze data stored in a cloud S3 bucket in-memory, avoiding costly transfer operations.\n\n## Where Does DuckDB Fit In?\n\n::: {.callout-tip}\n# How much data?\nDespite being in-memory, DuckDB allows analyses to \"spillover\" into the hard disk. What are the limits of this fallback?\n:::\n\n::: {.callout-tip}\n# Which process?\nWhat counts as a \"process\" for in-process? The authors discuss querying S3 files from a Cloud VM instance \"in process\" - is this a serverless deployment of Python? What's the \"process\" for the DuckDB CLI? \n::: \n\n## Where Not to Use DuckDB?\n\n- Tranformation and analysis of very large data sets \n- \"Steaming data\" in real-time without batching first (but see this DuckDB Lab's [blog post](https://duckdb.org/2025/10/13/duckdb-streaming-patterns))\n- Applications involving concurrent writes - traditional databases are still best for this.\n\n## How Can I use DuckDB?\n\n- Using SQL!\n- DuckDB has R and Python APIs that mirror dplyr and pandas syntax. \n- But the SQL API appears to get \"first class\" treatment.\n\n## Supported File Types\n\n- Parquet*\n- In-memory dataframes\n- CSV \n- JSON\n- Apache Arrow columnar shaped data\n- Cloud buckets like S3 or GCP\n- DuckDB database format (.duckdb)\n\n## DuckDB SQL\n- Supported data structures include \"traditional\" SQL ones: `varchar`, `numeric`, etc.\n- It also supports some data types not common for databases but well known in programming languaes: enums, lists, maps (dictionaries) and structs.\n\n## DuckDB SQL\n- DuckDB's [Friendly SQL](https://duckdb.org/docs/stable/sql/dialect/friendly_sql) eliminates some common SQL pain points.\n- For instance, you can select of the columns in a table using `SELECT *` instead of enumerating every column name.\n- DuckDB includes a range of aggregation functions, grouping functions, and support for SQL features like common table expressions.\n\n# Interacting with Bookclub Github Repository\n\n## Overview\n- The repo is at https://github.com/r4ds/bookclub-duckdb\n- We will write a \"book\" as we upload our presentations to this repo\n- Under the hood, the bookclub repository uses quarto and github actions to render a slick website  \n- The book covers a few different technologies. Here is how I have managed the Python, R and SQL dependencies \n\n## Fork and Clone\n\n- The repo contains excellent instructions for updating the repository using R and the `usethis` package.\n\n- If you do not use R, the gist is to create a personal fork of the repository, make your changes to that fork, and then push your changges back to main repository.\n\n- Make sure your fork is up to date with the main repository!\n\n## Edit Chapter Files\n\n- You can edit the `.qmd` file for the the chapter you are presenting under `/slides/xx.qmd`.\n- To render in a presentation-friendly, slideshow format use revealjs.\n- From the command line:\n```bash\nquarto render ~/bookclub-duckdb/slides/01.qmd --to revealjs\n```\n- Or using the `YAML` header:\n\n\n::: {.cell}\n\n```{.yaml .cell-code}\nformat: revealjs\n```\n:::\n\n\n- By default, slides render to `/_site/slides/xx.html`\n\n## Dependency Management   \n\n- To render the book chapters on your local machine, you need to load the R dependencies listed in the `DESCRIPTION` file. You need these even if your presentation has no R code in it. \n\n- There are no Python dependencies right now, but once we hit that point we will record them in `pyproject.toml` in the repository.\n\n## Installing R dependencies\n\n- Here is an automated way to load the correct R dependencies using `pak` and `renv`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Install pak and renv\nif (!requireNamespace(\"pak\", quietly = TRUE)) {\ninstall.packages(\"pak\", repos = sprintf(\n  \"https://r-lib.github.io/p/pak/stable/%s/%s/%s\",\n  .Platform$pkgType,\n  R.Version()$os,\n  R.Version()$arch\n))\n}\nif (!requireNamespace(\"renv\", quietly = TRUE)) {\n  pak::pkg_install(\"renv\")\n}\n## Configure renv to use pak to install packages\nrenv::config$pak.enabled(TRUE)\n## Configure renv to snapshot dependencies from the DESCRIPTION file\nrenv::settings$snapshot.type(\"explicit\")\n\n## Install the project dependencies\npak::pkg_install(renv::dependencies(path = \"DESCRIPTION\"))\n```\n:::\n\n\n## Installing Python dependencies \n- If you add any Python code to your presentation, you will need to add Python dependencies. \n- An easy way to do this is to [install UV](https://docs.astral.sh/uv/getting-started/installation/)\n- You can sync your local machine with the Python dependencies:\n```bash\nuv sync\nsource .venv/bin/activate\n```\n\n## Adding Packages\n\n- If you add any new R or Python packages to your local repository, you should make sure those dependencies get reflected in the main repository.\n- If you add R dependencies, make sure to update `DESCRIPTION` and commit the changes\n\n::: {.cell}\n\n```{.r .cell-code}\nusethis::use_package(\"duckdb\", min_version = TRUE)\n```\n:::\n\n\n- If you add Python dependencies, make sure to update `pyproject.toml` (UV does this automatically)\n\n```bash\n# install AND update pyproject.toml\nuv add duckdb \n```\n\n## Adding Packages\n- Generally, with this setup you should commit and push changes to `pyproject.toml` and `DESCRIPTION`, but *not* changes to `renv.lock` and `uv.lock`\n\n## SQL Chunks in Quarto\n- Quarto can execute SQL code chunks if we provide it an appropriate database backend (thanks to [this blog post](https://danielroelfs.com/posts/sql-notebooks-with-quarto/)).\n- You can define the database in R or Python, and then pass it as a quarto chunk option.\n- To create the database connection in R or Python:\n\n::: {.cell}\n\n```{.r .cell-code}\ncon_flights <- con_flights <- DBI::dbConnect(\n  drv = duckdb::duckdb(),\n  dbdir = \"./data/flights.duckdb\",\n  read_only = TRUE\n)\n```\n:::\n\n\nor, in Python \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport duckdb\ncon_flights = duckdb.connect('flights.duckdb', read_only=True)\n```\n:::\n\n\n## SQL Chunks in Quarto\nThen, to create the chunk:\n\n```sql\nSELECT name, carrier FROM airlines LIMIT 10;\n```\n\n## Quarto Execution Option - Freeze\n\n- The book covers a lot different technologies, and we may tire of troubleshooting dependencies in the main repo.\n\n- Quarto's \"freeze\" option is a quick fix to this issue. It will tell the rendering pipeline in the main repo not to render that chapter and instead pull the .html file from `_freeze/slides/xx/`.\n\n- In the top level YAML, use:\n```yaml\nexecute:\n  freeze: true\n```\n\n- If you use this method, make sure sure to commit changes to `_freeze/slides/xx` to the repository! \n\n## Next week\n- Chapter 2 is quite short and Chapter 3 is longer - should we bundle/split?",
    "supporting": [
      "01_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}